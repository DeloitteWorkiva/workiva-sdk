"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from datetime import datetime
from enum import Enum
import pydantic
from pydantic import field_serializer, model_serializer
from typing import Any, Dict, Optional
from typing_extensions import Annotated, NotRequired, TypedDict
from workiva import models, utils
from workiva.types import BaseModel, UNSET_SENTINEL


class Status(str, Enum, metaclass=utils.OpenEnumMeta):
    r"""The files's current status"""

    STAGING = "STAGING"
    STAGED = "STAGED"
    IMPORTING = "IMPORTING"
    IMPORTED = "IMPORTED"
    ERROR = "ERROR"


class FileMetaDtoTypedDict(TypedDict):
    column_mappings: NotRequired[Dict[str, str]]
    r"""Maps the columns in the physical file (CSV or JSON) to the columns in fact table = {\"physical_col1\":\"table_col1\", \"physical_col2\":\"table_col2\"}"""
    created: NotRequired[datetime]
    r"""When the entity was created"""
    delimiter: NotRequired[str]
    r"""The character to use as a delimiter within the file to separate one field from
    another.  The default is comma
    """
    id: NotRequired[str]
    r"""The entity's unique identifier"""
    key: NotRequired[str]
    r"""The key is here for backwards compatibility only and will always be an empty string."""
    metadata: NotRequired[Dict[str, Dict[str, Any]]]
    r"""The file's meta data"""
    name: NotRequired[str]
    r"""The name of the file"""
    num_errors: NotRequired[int]
    r"""Number of errors found in the file"""
    num_records: NotRequired[int]
    r"""Number of records imported from this file.  This will only be non-zero if the file is in the IMPORTED status."""
    original_file_size: NotRequired[int]
    r"""Size of the original file that was uploaded."""
    source: NotRequired[str]
    r"""URI that describes the source location of this file if imported from another system. For instance, this will have a spreadsheet URL if this file was imported from spreadsheets. This will be null if the file was uploaded using the data prep API."""
    status: NotRequired[Status]
    r"""The files's current status"""
    table_id: NotRequired[str]
    r"""The unique identifier for the table"""
    tags: NotRequired[Dict[str, str]]
    r"""The tags associated with the file"""
    updated: NotRequired[datetime]
    r"""When the entity was last updated"""
    user_id: NotRequired[str]
    r"""The owner of the entity"""
    version: NotRequired[int]
    r"""The version of the current representation of the entity"""


class FileMetaDto(BaseModel):
    column_mappings: Annotated[
        Optional[Dict[str, str]], pydantic.Field(alias="columnMappings")
    ] = None
    r"""Maps the columns in the physical file (CSV or JSON) to the columns in fact table = {\"physical_col1\":\"table_col1\", \"physical_col2\":\"table_col2\"}"""

    created: Optional[datetime] = None
    r"""When the entity was created"""

    delimiter: Optional[str] = None
    r"""The character to use as a delimiter within the file to separate one field from
    another.  The default is comma
    """

    id: Optional[str] = None
    r"""The entity's unique identifier"""

    key: Annotated[
        Optional[str],
        pydantic.Field(
            deprecated="warning: ** DEPRECATED ** - This will be removed in a future release, please migrate away from it as soon as possible."
        ),
    ] = None
    r"""The key is here for backwards compatibility only and will always be an empty string."""

    metadata: Optional[Dict[str, Dict[str, Any]]] = None
    r"""The file's meta data"""

    name: Optional[str] = None
    r"""The name of the file"""

    num_errors: Annotated[Optional[int], pydantic.Field(alias="numErrors")] = None
    r"""Number of errors found in the file"""

    num_records: Annotated[Optional[int], pydantic.Field(alias="numRecords")] = None
    r"""Number of records imported from this file.  This will only be non-zero if the file is in the IMPORTED status."""

    original_file_size: Annotated[
        Optional[int], pydantic.Field(alias="originalFileSize")
    ] = None
    r"""Size of the original file that was uploaded."""

    source: Optional[str] = None
    r"""URI that describes the source location of this file if imported from another system. For instance, this will have a spreadsheet URL if this file was imported from spreadsheets. This will be null if the file was uploaded using the data prep API."""

    status: Optional[Status] = None
    r"""The files's current status"""

    table_id: Annotated[Optional[str], pydantic.Field(alias="tableId")] = None
    r"""The unique identifier for the table"""

    tags: Optional[Dict[str, str]] = None
    r"""The tags associated with the file"""

    updated: Optional[datetime] = None
    r"""When the entity was last updated"""

    user_id: Annotated[Optional[str], pydantic.Field(alias="userId")] = None
    r"""The owner of the entity"""

    version: Optional[int] = None
    r"""The version of the current representation of the entity"""

    @field_serializer("status")
    def serialize_status(self, value):
        if isinstance(value, str):
            try:
                return models.Status(value)
            except ValueError:
                return value
        return value

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "columnMappings",
                "created",
                "delimiter",
                "id",
                "key",
                "metadata",
                "name",
                "numErrors",
                "numRecords",
                "originalFileSize",
                "source",
                "status",
                "tableId",
                "tags",
                "updated",
                "userId",
                "version",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


try:
    FileMetaDto.model_rebuild()
except NameError:
    pass
